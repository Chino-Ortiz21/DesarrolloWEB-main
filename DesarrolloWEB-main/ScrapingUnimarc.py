import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
import json
import re
from datetime import datetime
import time

# ==============================================================================
# ESTRATEGIA 1: INFERIR CATEGOR√çA DEL NOMBRE/DESCRIPCI√ìN DEL PRODUCTO
# Define tus categor√≠as y las palabras clave asociadas
# Actualizado para tus categor√≠as: Abarrotes, Bebidas, L√°cteos, Carnes, Frutas/Verduras,
# Beb√©s, Mascotas, Hogar, Ropa, Tecnolog√≠a, Juguetes, Farmacia
PRODUCT_CATEGORIES = {
    "Abarrotes": [
        "arroz", "pasta", "az√∫car", "sal", "harina", "aceite", "legumbre", "salsa",
        "caf√©", "t√©", "cereal", "mermelada", "at√∫n", "conserva", "galleta", "chocolate",
        "snacks", "pan de molde", "tortilla", "tostada", "condimento", "especia",
        "vinagre", "mostaza", "mayonesa", "ketchup", "miel", "muesli", "granola",
        "barrita", "sopa", "caldo", "cubo", "fideos", "harina", "premezcla", "levadura",
        "postre instant√°neo", "gelatina", "frutos secos", "semillas", "granos"
    ],
    "Bebidas": [
        "bebida", "jugo", "agua", "gaseosa", "n√©ctar", "cerveza", "vino", "alcohol",
        "espumante", "bebida isot√≥nica", "bebida energ√©tica", "bebida vegetal",
        "bebida cola", "limonada", "t√© helado", "soda", "refresco"
    ],
    "L√°cteos": [
        "leche", "yogurt", "queso", "mantequilla", "crema", "postre l√°cteo",
        "leche descremada", "leche semidescremada", "leche entera", "leche sin lactosa",
        "leche cultivada", "leche condensada", "manjar", "margarin", "quesillo",
        "ricotta", "reques√≥n", "probi√≥tico", "kefir"
    ],
    "Carnes": [
        "vacuno", "pollo", "cerdo", "pescado", "marisco", "carne", "embutido",
        "chorizo", "hamburguesa", "salchicha", "vienesas", "longaniza", "pavo",
        "cordero", "filete", "posta", "asado", "costilla", "escalopa", "molida",
        "jam√≥n", "mortadela", "pat√©", "prieta", "ave"
    ],
    "Frutas/Verduras": [
        "manzana", "pl√°tano", "naranja", "palta", "tomate", "lechuga", "cebolla",
        "papa", "fruta", "verdura", "vegetal", "zanahoria", "zapallo", "pimiento",
        "lim√≥n", "kiwi", "uva", "sand√≠a", "mel√≥n", "pera", "durazno", "cereza",
        "apio", "br√≥coli", "coliflor", "espinaca", "champignon", "aj√≠", "champi√±√≥n"
    ],
    "Beb√©s": [
        "pa√±al", "toallita h√∫meda", "papilla", "colado", "cereal beb√©", "leche infantil",
        "f√≥rmula beb√©", "mamadera", "chupete", "biber√≥n", "crema beb√©", "shampoo beb√©",
        "talco beb√©", "juguete beb√©", "beb√©", "infantil"
    ],
    "Mascotas": [
        "alimento perro", "comida gato", "juguete mascota", "arena gato",
        "snack perro", "mascotas", "comida para perro", "comida para gato",
        "antipulgas", "collar", "correa", "juguete para" # "para" puede ser muy gen√©rico, usar con cautela
    ],
    "Hogar": [
        "limpiador", "detergente", "lavalozas", "cloro", "suavizante", "papel higi√©nico",
        "toalla", "basura", "desodorante ambiental", "insecticida", "lustramuebles",
        "esponja", "escobilla", "balde", "secador", "trapeador", "jab√≥n de ropa",
        "servilleta", "film", "aluminio", "bolsa de basura", "guante", "limpiavidrios",
        "ambientador", "pilas", "ampolleta", "foco", "vela", "encendedor"
    ],
    "Ropa": [
        "calcetines", "medias", "camiseta", "polera", "pantal√≥n", "ropa interior",
        "chaqueta", "polar", "zapatilla", "sandalia", "pijama", "traje de ba√±o",
        "vestido", "falda", "poler√≥n", "cortaviento"
        # Es muy probable que estos no se encuentren en Unimarc, pero se incluyen por tu lista.
    ],
    "Tecnolog√≠a": [
        "aud√≠fono", "cargador", "cable", "pilas", "bater√≠a", "smart", "tablet",
        "celular", "impresora", "cartucho", "toner", "computador", "monitor",
        "teclado", "mouse", "parlante", "auricular"
        # Muy poco probable encontrar esto en Unimarc, pero se incluyen.
    ],
    "Juguetes": [
        "mu√±eca", "auto de juguete", "peluche", "bloques", "lego", "puzzles",
        "juego de mesa", "figura de acci√≥n", "juguete", "did√°ctico"
        # Podr√≠a haber algunos juguetes peque√±os, especialmente en √©pocas festivas.
    ],
    "Farmacia": [
        "analg√©sico", "paracetamol", "ibuprofeno", "vitamina", "suplemento",
        "pastilla", "jarabe", "medicamento", "botiqu√≠n", "ap√≥sito", "curita",
        "algod√≥n", "alcohol", "agua oxigenada", "anti√°cido", "laxante", "term√≥metro",
        "mascarilla", "gel sanitizante", "test covid", "preservativo", "salud", "higiene femenina",
        "protector solar", "loci√≥n"
        # Es posible que Unimarc venda algunos productos de parafarmacia o primeros auxilios.
    ]
}

def classify_product_category(product_name, product_description=""):
    """
    Clasifica un producto en una categor√≠a bas√°ndose en palabras clave en su nombre o descripci√≥n.
    Prioriza las coincidencias m√°s espec√≠ficas o m√°s largas si es necesario.
    """
    text_to_analyze = (product_name + " " + product_description).lower()
    
    # Ordenar las categor√≠as por la longitud total de las palabras clave de forma descendente
    # para intentar capturar primero las categor√≠as con palabras clave m√°s espec√≠ficas o m√°s largas.
    sorted_categories = sorted(PRODUCT_CATEGORIES.items(), key=lambda item: sum(len(k) for k in item[1]), reverse=True)

    for category, keywords in sorted_categories:
        for keyword in keywords:
            # Usar \b para coincidencia de palabra completa (word boundary) para mayor precisi√≥n.
            # Por ejemplo, para evitar que "man" de "mantequilla" coincida con "manzana".
            # Es importante asegurarse de que las palabras clave en PRODUCT_CATEGORIES no incluyan
            # espacios al principio/final si se usa \b.
            if re.search(r'\b' + re.escape(keyword.lower()) + r'\b', text_to_analyze):
                return category
    
    return "Otros" # Categor√≠a por defecto si no se encuentra ninguna coincidencia
# ==============================================================================


class UnimarcScraper:
    def __init__(self, headless=True, debug=False):
        self.base_url = "https://www.unimarc.cl"
        self.ofertas_url_base = "https://www.unimarc.cl/ofertas/ofertas-unimarc" # Base URL for offers
        self.headless = headless
        self.debug = debug
        self.driver = None
        self.wait = None
        
    def setup_driver(self):
        """Configura el driver de Selenium"""
        chrome_options = Options()
        if self.headless:
            chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-plugins")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # Suprimir logs innecesarios
        chrome_options.add_argument("--log-level=3")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.wait = WebDriverWait(self.driver, 15)
            print("Driver configurado exitosamente")
            if not self.headless:
                print("Navegador visible abierto - puedes ver lo que est√° haciendo")
        except Exception as e:
            print(f"Error al configurar el driver: {e}")
            print("Aseg√∫rate de tener ChromeDriver instalado y en el PATH.")
            print("Puedes instalarlo con 'pip install webdriver-manager' y luego usar 'webdriver_manager.chrome.ChromeDriverManager().install()'.")
            return False
        return True
    
    def close_driver(self):
        """Cierra el driver"""
        if self.driver and not self.debug:
            self.driver.quit()
        elif self.debug:
            input("Presiona Enter para cerrar el navegador...")
            self.driver.quit()
    
    def clean_text(self, text):
        """Limpia y normaliza el texto"""
        if not text:
            return ""
        return re.sub(r'\s+', ' ', text.strip())
    
    def extract_price(self, price_text):
        """
        Extrae el precio num√©rico (float) del texto, manejando formato chileno (punto para miles, coma para decimales).
        """
        if self.debug:
            print(f"DEBUG: Input a extract_price: '{price_text}'")

        if not price_text:
            if self.debug:
                print("DEBUG: Input de precio vac√≠o.")
            return None
        
        # Eliminar s√≠mbolos de moneda y otros caracteres no num√©ricos, excepto puntos y comas
        clean_text = re.sub(r'[^\d.,]', '', str(price_text))
        if self.debug:
            print(f"DEBUG: Texto limpio antes de normalizar: '{clean_text}'")

        # Normalizar el formato chileno a formato est√°ndar de float (punto decimal)
        if ',' in clean_text and '.' in clean_text:
            # Si hay ambos, y la coma es el √∫ltimo separador, asumimos coma decimal. Ej: "1.234,50" -> "1234.50"
            if clean_text.rfind(',') > clean_text.rfind('.'):
                clean_text = clean_text.replace('.', '').replace(',', '.')
            else: # Si el punto es el √∫ltimo separador, asumimos punto decimal. Ej: "1,234.50" (menos com√∫n en Chile)
                clean_text = clean_text.replace(',', '') # Remover comas de miles
        elif ',' in clean_text:
            clean_text = clean_text.replace(',', '.')
        elif '.' in clean_text:
            # Si solo hay puntos, asumimos puntos de miles, a menos que sea un n√∫mero peque√±o como "1.5"
            # Si tiene solo un punto y menos de 3 d√≠gitos despu√©s, asumimos decimal
            if clean_text.count('.') == 1 and len(clean_text.split('.')[-1]) < 3:
                pass # Ya est√° en formato decimal correcto
            else: # Asumir que son miles
                clean_text = clean_text.replace('.', '')
                
        if self.debug:
            print(f"DEBUG: Texto limpio despu√©s de normalizar: '{clean_text}'")

        try:
            price_val = float(clean_text)
            # Validar que sea un precio realista (ej. entre 10 y 10,000,000 CLP)
            if 10 <= price_val <= 10000000:
                if self.debug:
                    print(f"DEBUG: Precio extra√≠do (float): {price_val}")
                return price_val
            else:
                if self.debug:
                    print(f"DEBUG: Precio {price_val} fuera de rango realista.")
                return None
        except ValueError:
            if self.debug:
                print(f"DEBUG: ValueError al convertir '{clean_text}' a float.")
            return None
        return None
    
    def wait_and_scroll(self):
        """Espera a que la p√°gina cargue los contenedores de productos y luego hace scroll para cargar m√°s contenido din√°mico."""
        print("Esperando a que los productos en la p√°gina carguen completamente y haciendo scroll...")
        
        try:
            # Esperar a que al menos un contenedor de producto est√© presente
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'section[id^="shelf__vertical--"].smu-impressed')))
            print("Contenedores de productos iniciales cargados.")
        except TimeoutException:
            print("La p√°gina tard√≥ demasiado en cargar los contenedores de productos. Continuando con el scroll.")
            
        scroll_height = self.driver.execute_script("return document.body.scrollHeight")
        last_scroll_height = 0
        scroll_attempts = 0
        max_scroll_attempts = 5 # Limitar los intentos para evitar bucles infinitos
        
        while scroll_height > last_scroll_height and scroll_attempts < max_scroll_attempts:
            last_scroll_height = scroll_height
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2) # Pausa para que cargue el lazy loading
            scroll_height = self.driver.execute_script("return document.body.scrollHeight")
            scroll_attempts += 1
            if self.debug:
                print(f"DEBUG: Scrolled. Current height: {scroll_height}, Attempts: {scroll_attempts}")
        
        self.driver.execute_script("window.scrollTo(0, 0);") # Volver al inicio
        time.sleep(1)
        print("Scroll completado.")
        
    def find_product_containers(self):
        """Encuentra contenedores de productos usando los selectores m√°s precisos."""
        # Basado en el HTML completo proporcionado, el contenedor m√°s fiable es la secci√≥n.
        # <section class="baseContainer_container__TSgMX ... smu-impressed" role="" id="shelf__vertical--hamburguesa-vacuno-la-crianza-premium-1-kg" ...>
        selectors_to_try = [
            'section[id^="shelf__vertical--"].smu-impressed', # Selector principal y m√°s espec√≠fico
            'div.baseContainer_container__TSgMX.ab__shelves.abc__shelves.baseContainer_justify-start___sjrG', # Contenedor externo del card (si la secci√≥n no funciona)
        ]
        
        all_potential_products = []
        
        for selector in selectors_to_try:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    all_potential_products.extend(elements)
                    if self.debug:
                        print(f"DEBUG: Encontrados {len(elements)} elementos con selector: '{selector}'")
            except Exception as e:
                if self.debug:
                    print(f"DEBUG: Selector '{selector}' fall√≥: {e}")
                continue
        
        unique_products = []
        seen_product_identifiers = set() 
        
        for product_elem in all_potential_products:
            try:
                # Usar la URL del producto como identificador √∫nico si es posible
                # Buscar el enlace principal dentro de este contenedor de producto
                product_link_elem = product_elem.find_elements(By.CSS_SELECTOR, 
                    'div[id="shelf__title"] > a.Link_link___5dmQ[href*="/product/"]')
                product_url = ''
                if product_link_elem:
                    href = product_link_elem[0].get_attribute('href')
                    if href and href.startswith('/product/'):
                        product_url = self.base_url + href
                    elif href and self.base_url in href:
                        product_url = href
                
                # Si tenemos una URL √∫nica, la usamos. Si no, usamos el innerHTML como antes.
                identifier = product_url if product_url else hash(product_elem.get_attribute('innerHTML'))

                if identifier in seen_product_identifiers:
                    continue # Ya procesado
                
                # Heur√≠sticas para validar si es un producto real (puede que el selector sea demasiado amplio)
                has_name = bool(product_elem.find_elements(By.CSS_SELECTOR, 'p.Shelf_nameProduct__CXI5M'))
                has_offer_price = bool(product_elem.find_elements(By.CSS_SELECTOR, 'p[id^="listPrice__offerPrice--discountprice-"]'))
                has_img = bool(product_elem.find_elements(By.TAG_NAME, 'img'))
                
                if has_name and has_offer_price and has_img: # Requerir estos elementos clave
                    unique_products.append(product_elem)
                    seen_product_identifiers.add(identifier)
                    
            except Exception as e:
                if self.debug:
                    print(f"DEBUG: Error al validar elemento potencial de producto: {e}")
                continue
        
        print(f"Total productos √∫nicos y v√°lidos encontrados: {len(unique_products)}")
        return unique_products
    
    def extract_product_data(self, product_element, index):
        """Extrae datos de un elemento de producto usando los selectores precisos."""
        product_data = {
            'nombre': '',
            'descripcion': '',
            'precio_original': None, 
            'precio_oferta': None,   
            'marca': '',
            'categoria': 'Desconocida', # Por defecto, ser√° actualizado por la funci√≥n
            'imagen': '',
            'url_producto': '',
            'fecha_scraping': datetime.now().isoformat()
        }
        
        try:
            if self.debug:
                print(f"\n--- PROCESANDO PRODUCTO {index} ---")
            
            # El HTML proporcionado indica que la URL, nombre y marca est√°n dentro del div con id="shelf__title"
            shelf_title_div = product_element.find_elements(By.ID, 'shelf__title')
            
            if shelf_title_div:
                main_product_link = shelf_title_div[0].find_elements(By.CSS_SELECTOR, 'a.Link_link___5dmQ.Link_link--none__BjwPj[href*="/product/"]')
            else:
                # Si no se encuentra shelf__title, buscar el enlace principal directamente en el product_element
                main_product_link = product_element.find_elements(By.CSS_SELECTOR, 'a.Link_link___5dmQ.Link_link--none__BjwPj[href*="/product/"]')

            if main_product_link:
                href = main_product_link[0].get_attribute('href')
                if href:
                    if href.startswith('/product/'):
                        product_data['url_producto'] = self.base_url + href
                    else:
                        product_data['url_producto'] = href
                
                # Extraer nombre del <p> con clase Shelf_nameProduct__CXI5M dentro del enlace
                name_elem = main_product_link[0].find_elements(By.CSS_SELECTOR, 'p.Shelf_nameProduct__CXI5M')
                if name_elem:
                    product_data['nombre'] = self.clean_text(name_elem[0].text)
                    product_data['descripcion'] = product_data['nombre'] # Descripci√≥n es el mismo nombre por ahora
                
                # Extraer marca del <p> con clase Shelf_brandText__sGfsS dentro del enlace
                brand_elem = main_product_link[0].find_elements(By.CSS_SELECTOR, 'p.Shelf_brandText__sGfsS')
                if brand_elem:
                    product_data['marca'] = self.clean_text(brand_elem[0].text)

            # Extraer Imagen del Producto
            # La imagen tambi√©n est√° dentro del enlace principal, o en un div de imagen dentro del contenedor general.
            img_elem = product_element.find_elements(By.CSS_SELECTOR, 'img[src*="unimarc.vtexassets.com"]')
            if img_elem:
                src = img_elem[0].get_attribute('src') or img_elem[0].get_attribute('data-src')
                if src and (src.startswith('http') or src.startswith('//') or src.startswith('/')):
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/') and not src.startswith(self.base_url):
                        src = self.base_url + src
                    product_data['imagen'] = src

            # Extraer Precio de Oferta
            offer_price_selectors = [
                'p[id^="listPrice__offerPrice--discountprice-"][class*="Text_text--xl__l05SR"]',
                'p.Text_text--xl__l05SR', # More general class for large text, often prices
                'p[class*="price"]', # Generic price class
                'span[class*="price"]',
                'div[class*="price"]'
            ]
            for selector in offer_price_selectors:
                try:
                    offer_price_elem = product_element.find_elements(By.CSS_SELECTOR, selector)
                    if offer_price_elem:
                        # Prioritize the one that contains '$' and is not empty
                        for elem in offer_price_elem:
                            if '$' in elem.text and self.clean_text(elem.text):
                                numeric_offer_price = self.extract_price(elem.text)
                                if numeric_offer_price is not None:
                                    product_data['precio_oferta'] = f"${numeric_offer_price:,.0f}".replace(",", ".")
                                    if self.debug:
                                        print(f"DEBUG: Oferta encontrada con selector '{selector}': {elem.text}")
                                    break # Found a valid offer price, move on
                        if product_data['precio_oferta'] is not None:
                            break # Break from outer loop if price found
                except Exception as e:
                    if self.debug:
                        print(f"DEBUG: Fallo al intentar selector de oferta '{selector}': {e}")
                    continue
            
            # Extraer Precio Original (tachado)
            original_price_selectors = [
                'p[id^="listPrice__offerPrice--listprice-"][class*="Text_text--line-through__1V_2e"]',
                'p.Text_text--line-through__1V_2e', # More general class for line-through text
                'span[class*="line-through"]', # Generic line-through class
                'div[class*="line-through"]',
                'p[class*="old-price"]',
                'span[class*="old-price"]',
                'div[class*="old-price"]'
            ]
            for selector in original_price_selectors:
                try:
                    original_price_elem = product_element.find_elements(By.CSS_SELECTOR, selector)
                    if original_price_elem:
                        for elem in original_price_elem:
                            if '$' in elem.text and self.clean_text(elem.text):
                                numeric_original_price = self.extract_price(elem.text)
                                if numeric_original_price is not None:
                                    product_data['precio_original'] = f"${numeric_original_price:,.0f}".replace(",", ".")
                                    if self.debug:
                                        print(f"DEBUG: Original encontrado con selector '{selector}': {elem.text}")
                                    break # Found a valid original price, move on
                        if product_data['precio_original'] is not None:
                            break # Break from outer loop if price found
                except Exception as e:
                    if self.debug:
                        print(f"DEBUG: Fallo al intentar selector original '{selector}': {e}")
                    continue

            # Asignar categor√≠a utilizando la funci√≥n de clasificaci√≥n
            product_data['categoria'] = classify_product_category(product_data['nombre'], product_data['descripcion'])


            if self.debug:
                print(f"DEBUG: Datos extra√≠dos para producto {index}:")
                for key, value in product_data.items():
                    if key != 'fecha_scraping' and (value is not None and value != ''):
                        print(f"  {key}: {value}")
                if product_data['precio_oferta'] is None:
                    print(f"DEBUG: Precio de oferta para producto {product_data['nombre'][:30]}... no capturado.")
                if product_data['precio_original'] is None:
                    print(f"DEBUG: Precio original para producto {product_data['nombre'][:30]}... no capturado.")
            
        except Exception as e:
            print(f"ERROR: Error extrayendo datos del producto {index}: {e}")
        
        return product_data
    
    def scrape_ofertas(self):
        """Realiza el scraping de ofertas"""
        if not self.setup_driver():
            return []
        
        all_products_data = []
        current_page_num = 1
        # Establece un l√≠mite bajo para pruebas. Cambiar a None o un n√∫mero alto para raspar todo.
        max_pages_to_scrape = None # Cambiado a 10 p√°ginas para pruebas
        
        try:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Navegando a la p√°gina de ofertas: {self.ofertas_url_base}")
            self.driver.get(self.ofertas_url_base)
            
            if not self.headless:
                print("üîç Navegador visible abierto - puedes ver lo que est√° haciendo")
            
            while True:
                if max_pages_to_scrape is not None and current_page_num > max_pages_to_scrape:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] L√≠mite de {max_pages_to_scrape} p√°ginas alcanzado. Terminando paginaci√≥n.")
                    break

                print(f"\n[{datetime.now().strftime('%H:%M:%S')}] --- Procesando P√°gina {current_page_num} ---")
                
                # Esperar y hacer scroll para cargar contenido din√°mico
                self.wait_and_scroll()
                
                print(f"[{datetime.now().strftime('%H:%M:%S')}] Buscando contenedores de productos en P√°gina {current_page_num}...")
                products_on_page = self.find_product_containers()
                
                if not products_on_page and current_page_num == 1:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå No se encontraron productos en la primera p√°gina con los selectores y heur√≠sticas actuales.")
                    if not self.headless:
                        input("Presiona Enter para continuar (revisa la p√°gina manualmente si quieres intentar depurar)...")
                    break # Salir si no hay productos en la primera p√°gina
                elif not products_on_page and current_page_num > 1:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] No se encontraron m√°s productos en la p√°gina {current_page_num}. Fin de la paginaci√≥n.")
                    break # Fin de la paginaci√≥n

                print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚úì Procesando {len(products_on_page)} elementos de productos √∫nicos en P√°gina {current_page_num}...")
                
                for i, product_element in enumerate(products_on_page):
                    try:
                        if self.debug or not self.headless:
                            # Resaltar el elemento actual para visualizaci√≥n en modo no-headless
                            self.driver.execute_script(
                                "arguments[0].style.border='3px solid red'; arguments[0].scrollIntoView({block: 'center'});", product_element)
                            time.sleep(0.1) # Pausa corta para visualizaci√≥n
                        
                        product_info = self.extract_product_data(product_element, i+1)
                        
                        if (product_info['nombre'] or 
                            product_info['precio_oferta'] is not None or 
                            product_info['precio_original'] is not None):
                            all_products_data.append(product_info)
                            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚úì Producto {i+1} (P√°g {current_page_num}) agregado: {product_info['nombre'][:50]}... (Oferta: {product_info['precio_oferta']})")
                        else:
                            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ö† Producto {i+1} (P√°g {current_page_num}) sin datos suficientes para ser √∫til. Saltando.")
                            
                        if self.debug or not self.headless:
                            # Quitar resaltado
                            self.driver.execute_script(
                                "arguments[0].style.border='';", product_element)
                            
                    except StaleElementReferenceException:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ö† Elemento estancado (StaleElementReferenceException) para producto {i+1} en P√°gina {current_page_num}. Reintentando o saltando.")
                        continue
                    except Exception as e:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Error procesando producto {i+1} (P√°g {current_page_num}): {e}")
                        continue
                
                # --- L√≥gica de Paginaci√≥n ---
                next_page_arrow_link = None
                try:
                    # Esperar un momento adicional para que los elementos de paginaci√≥n se rendericen
                    time.sleep(2) 

                    # Construir el selector CSS para el enlace de la flecha derecha (siguiente p√°gina)
                    # La URL del enlace a la p√°gina 2 es "/ofertas/ofertas-unimarc?&amp;page=2"
                    # Usamos '&page=' para mayor compatibilidad con & y &amp;
                    target_next_page_url_segment = f"/ofertas/ofertas-unimarc?&page={current_page_num + 1}"
                    
                    # Intentar encontrar el enlace exacto a la siguiente p√°gina y esperar a que sea clicable
                    # Buscamos el <a> que contenga el SVG con id="ArrowRightNavigate" y el href de la siguiente p√°gina.
                    # El selector CSS para esto ser√≠a:
                    # a[href*="/ofertas/ofertas-unimarc?&page={next_page_num_expected}"] svg#ArrowRightNavigate
                    # Sin embargo, el click debe ser en el <a>, no en el SVG.
                    # Vamos a buscar el <a> que tenga el href correcto y dentro tenga el SVG.
                    
                    # XPath es m√°s flexible para esto:
                    # //a[contains(@href, '{target_next_page_url_segment}') and .//*[name()='svg' and @id='ArrowRightNavigate']]
                    
                    next_page_num_expected = current_page_num + 1
                    
                    xpath_for_next_arrow = f'//a[contains(@href, "page={next_page_num_expected}") and .//*[name()="svg" and @id="ArrowRightNavigate"]]'

                    if self.debug:
                        print(f"DEBUG: Buscando enlace de flecha derecha para la p√°gina {next_page_num_expected} con XPath: {xpath_for_next_arrow}")

                    next_page_arrow_link = self.wait.until(
                        EC.element_to_be_clickable((By.XPATH, xpath_for_next_arrow)),
                        f"No se encontr√≥ el enlace de flecha derecha clicable para la p√°gina {next_page_num_expected}."
                    )
                    
                    if self.debug:
                        print(f"DEBUG: ‚úÖ Enlace de flecha derecha a p√°gina {next_page_num_expected} encontrado y clicable: {next_page_arrow_link.get_attribute('href')}")
                        
                except TimeoutException as te:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Timeout al buscar el enlace de paginaci√≥n: {te}. Fin de la paginaci√≥n.")
                    break # No hay m√°s p√°ginas o el enlace no apareci√≥ a tiempo
                except NoSuchElementException as nsee:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Enlace de paginaci√≥n no encontrado: {nsee}. Fin de la paginaci√≥n.")
                    break
                except Exception as e:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Error inesperado en la l√≥gica de paginaci√≥n al encontrar enlaces: {e}. Terminando paginaci√≥n.")
                    break

                # Si se encontr√≥ y es clicable, hacemos clic y esperamos la carga de la nueva p√°gina.
                if next_page_arrow_link:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] Haciendo clic en el enlace de la flecha a la p√°gina siguiente: {next_page_arrow_link.get_attribute('href')}")
                    
                    # Store the URL before click to confirm it changes
                    old_url = self.driver.current_url
                    
                    try:
                        # Desplazarse al elemento para asegurar que sea visible y clicable
                        self.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", next_page_arrow_link)
                        time.sleep(1) # Peque√±a pausa para el scroll
                        
                        next_page_arrow_link.click() # Hacer clic en el enlace de la flecha de la siguiente p√°gina

                        # Esperar a que la URL cambie A LA URL DE LA SIGUIENTE P√ÅGINA ESPEC√çFICA
                        expected_new_url_pattern = f"{self.ofertas_url_base}\\?.*page={current_page_num + 1}"
                        self.wait.until(EC.url_matches(expected_new_url_pattern),
                                        f"La URL no cambi√≥ a la esperada ({expected_new_url_pattern}) despu√©s de hacer clic.")
                        
                        # Despu√©s de que la URL cambie, esperar que los elementos de productos en la *nueva* p√°gina est√©n presentes
                        self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'section[id^="shelf__vertical--"].smu-impressed')),
                                        "No se encontraron productos en la nueva p√°gina despu√©s del cambio de URL.")
                        
                        current_page_num += 1 # Incrementar el n√∫mero de p√°gina actual solo despu√©s de una navegaci√≥n exitosa
                        time.sleep(3) # Dar tiempo adicional para que el contenido se renderice completamente
                    except StaleElementReferenceException:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ö† El enlace de la p√°gina siguiente se volvi√≥ obsoleto al hacer clic. Terminando paginaci√≥n.")
                        break
                    except TimeoutException as te:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå La nueva p√°gina no carg√≥ despu√©s de hacer clic en el enlace: {te}. Terminando paginaci√≥n.")
                        break
                    except Exception as e:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Error al hacer clic o esperar la carga de la nueva p√°gina: {e}. Terminando paginaci√≥n.")
                        break
                else:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] No se encontr√≥ un enlace v√°lido a la siguiente p√°gina. Fin de la paginaci√≥n.")
                    break
            
            print(f"\n[{datetime.now().strftime('%H:%M:%S')}] üéâ Scraping completado. {len(all_products_data)} productos extra√≠dos.")
            return all_products_data
            
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Error inesperado durante el scraping: {e}")
            return []
        finally:
            self.close_driver() # Siempre cerrar el driver
    
    def save_to_json(self, data, filename=None):
        """Guarda los datos en un archivo JSON"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"unimarc_ofertas_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str) 
            print(f"[{datetime.now().strftime('%H:%M:%S')}] üíæ Datos guardados en: {filename}")
            return filename
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ‚ùå Error al guardar el archivo: {e}")
            return None

def main():
    """Funci√≥n principal para ejecutar el scraper"""
    print("=== üõí SCRAPER UNIMARC OFERTAS ===")
    print("Nota: Este script utiliza Selenium y requiere ChromeDriver.")
    print("Si encuentras problemas, verifica tu instalaci√≥n de ChromeDriver.")
    print()
    
    # Configuraciones interactivas
    headless_input = input("¬øEjecutar en modo headless (sin ventana del navegador visible)? (y/n, default=n): ").lower()
    headless = headless_input == 'y' or headless_input == '' 
    
    debug_input = input("¬øActivar modo debug (m√°s informaci√≥n y navegador abierto al final si no es headless)? (y/n, default=n): ").lower()
    debug = debug_input == 'y'
    
    scraper = UnimarcScraper(headless=headless, debug=debug)
    
    try:
        # Realizar scraping
        productos = scraper.scrape_ofertas()
        
        if productos:
            # Guardar en JSON
            filename = scraper.save_to_json(productos)
            
            # Mostrar estad√≠sticas
            print(f"\n=== üìä RESUMEN DEL SCRAPING ===")
            print(f"Total productos extra√≠dos: {len(productos)}")
            print(f"Productos con nombre: {len([p for p in productos if p['nombre']])}")
            print(f"Productos con precio de oferta: {len([p for p in productos if p['precio_oferta'] is not None])}")
            print(f"Productos con precio original: {len([p for p in productos if p['precio_original'] is not None])}")
            print(f"Productos con imagen: {len([p for p in productos if p['imagen']])}")
            print(f"Productos con URL: {len([p for p in productos if p['url_producto']])}")
            print(f"Archivo JSON guardado en: {filename if filename else 'Error al guardar'}")
            
            # Mostrar algunos ejemplos de productos
            print(f"\n=== üîç EJEMPLOS DE PRODUCTOS EXTRA√çDOS (primeros 5) ===")
            valid_products_sample = [p for p in productos if p['nombre'] or p['precio_oferta']][:5]
            for i, producto in enumerate(valid_products_sample):
                print(f"\nüì¶ Producto {i+1}:")
                # Los precios ahora son cadenas, se imprimen directamente
                print(f"  üìù Nombre: {producto['nombre'] or 'N/A'}")
                print(f"  üí∞ Precio Original: {producto['precio_original'] or 'N/A'}")
                print(f"  üè∑Ô∏è Precio Oferta: {producto['precio_oferta'] or 'N/A'}")
                print(f"  üñºÔ∏è URL Imagen: {'‚úì' if producto['imagen'] else '‚úó'}")
                print(f"  üîó URL Producto: {'‚úì' if producto['url_producto'] else '‚úó'}")
                print(f"  üè∑Ô∏è Categor√≠a: {producto['categoria'] or 'N/A'}") # Mostrar la categor√≠a
        else:
            print("\n‚ùå No se encontraron productos o hubo un error grave durante el scraping.")
            print("üí° Sugerencias:")
            print("  - Intenta ejecutar el script sin modo headless (responde 'n' a la primera pregunta) para ver la p√°gina cargando.")
            print("  - Activa el modo debug (responde 'y' a la segunda pregunta) para ver m√°s detalles en la consola.")
            print("  - Aseg√∫rate de tener una conexi√≥n a internet estable y que la URL de Unimarc est√© accesible.")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Scraping interrumpido por el usuario.")
    except Exception as e:
        print(f"‚ùå Error inesperado en la funci√≥n principal: {e}")

if __name__ == "__main__":
    main()
